#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Database Statistics Extractor
ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ëª¨ë“  í†µê³„ ë°ì´í„°ë¥¼ ì¶”ì¶œí•˜ì—¬ í…ìŠ¤íŠ¸ë¡œ ì¶œë ¥í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸

ì¶”ì¶œ í•­ëª©:
1. ì´ ë¡œê·¸ì¸ìˆ˜
2. ì´ ê²€ìƒ‰ìˆ˜
3. ì´ ë¦¬í¬íŠ¸ìƒì„±ìˆ˜
4. ì´ íšŒì›ìˆ˜
5. ì´ ìœ ë£ŒíšŒì›ìˆ˜
6. ì´ ë¬´ë£ŒíšŒì›ìˆ˜
7. ì´ ê²€ìƒ‰ì–´(100ì¼ê°„ì˜ dbì €ì¥)
8. ì´ ë¦¬í¬íŠ¸ ì œëª©(100ì¼ê°„ì˜ dbì €ì¥)
9. í‰ê·  ë¡œê·¸ì¸ ìˆ˜ = ì´ ë¡œê·¸ì¸ ìˆ˜ / ì´ íšŒì›ìˆ˜
10. í‰ê·  ê²€ìƒ‰ ìˆ˜ = ì´ ê²€ìƒ‰ ìˆ˜ / ì´ íšŒì›ìˆ˜
11. í‰ê·  ë¦¬í¬íŠ¸ ìƒì„± ìˆ˜ = ì´ ë¦¬í¬íŠ¸ ìƒì„± ìˆ˜ / ì´ íšŒì›ìˆ˜
12. ë¡œê·¸ì¸â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨ = ë¡œê·¸ì¸ ê±´ìˆ˜ ëŒ€ë¹„ ë¦¬í¬íŠ¸ ìƒì„± ê±´ìˆ˜
13. ê²€ìƒ‰â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨ = ê²€ìƒ‰ ê±´ìˆ˜ ëŒ€ë¹„ ë¦¬í¬íŠ¸ ìƒì„± ê±´ìˆ˜
14. í‚¤ì›Œë“œ ë¶„ì„ = ì „ì²´ íšŒì› í‚¤ì›Œë“œ ì‚¬ìš© íŒ¨í„´
15. ë¦¬í¬íŠ¸ ë¶„ì„ = ì „ì²´ íšŒì› ë¦¬í¬íŠ¸ ìƒì„± íŒ¨í„´
16. ì‚¬ìš©ì ë¶„í¬ = ë¬´ë£ŒíšŒì› vs ì •ê¸°êµ¬ë…íšŒì›
"""

import requests
import json
import os
import sys
from datetime import datetime, timedelta
from collections import Counter, defaultdict
from dotenv import load_dotenv
import colorlog

# ë¡œê¹… ì„¤ì •
handler = colorlog.StreamHandler()
handler.setFormatter(colorlog.ColoredFormatter(
    '%(log_color)s%(levelname)-8s%(reset)s %(blue)s%(message)s',
    datefmt=None,
    reset=True,
    log_colors={
        'DEBUG': 'cyan',
        'INFO': 'green',
        'WARNING': 'yellow',
        'ERROR': 'red',
        'CRITICAL': 'red,bg_white',
    },
    secondary_log_colors={},
    style='%'
))

logger = colorlog.getLogger()
logger.addHandler(handler)
logger.setLevel(colorlog.INFO)

class DatabaseStatisticsExtractor:
    def __init__(self):
        """ì´ˆê¸°í™” ë° í™˜ê²½ë³€ìˆ˜ ë¡œë“œ"""
        load_dotenv('.env.python')
        
        self.supabase_url = os.getenv('SUPABASE_URL')
        self.supabase_service_key = os.getenv('SUPABASE_SERVICE_ROLE_KEY')
        
        if not all([self.supabase_url, self.supabase_service_key]):
            logger.error("Supabase í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            sys.exit(1)
        
        self.headers = {
            'apikey': self.supabase_service_key,
            'Authorization': f'Bearer {self.supabase_service_key}',
            'Content-Type': 'application/json',
            'Prefer': 'return=representation'
        }
        
        # í†µê³„ ë°ì´í„° ì €ì¥ìš©
        self.stats = {}
        
        logger.info("Database Statistics Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def check_connection(self):
        """ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸"""
        try:
            response = requests.get(
                f"{self.supabase_url}/rest/v1/users?select=count",
                headers=self.headers,
                timeout=10
            )
            if response.status_code == 200:
                logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì„±ê³µ")
                return True
            else:
                logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {response.status_code}")
                return False
        except Exception as e:
            logger.error(f"âŒ ì—°ê²° ì˜¤ë¥˜: {str(e)}")
            return False
    
    def get_table_data(self, table_name, select_fields="*", filters=None, limit=None):
        """í…Œì´ë¸” ë°ì´í„° ì¡°íšŒ"""
        try:
            url = f"{self.supabase_url}/rest/v1/{table_name}?select={select_fields}"
            
            if filters:
                for key, value in filters.items():
                    url += f"&{key}={value}"
            
            if limit:
                url += f"&limit={limit}"
            
            logger.info(f"ğŸ” ìš”ì²­ URL: {url}")
            response = requests.get(url, headers=self.headers, timeout=30)
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"ğŸ“Š {table_name} í…Œì´ë¸”ì—ì„œ {len(data)}ê±´ ì¡°íšŒ")
                return data
            else:
                logger.error(f"âŒ {table_name} í…Œì´ë¸” ì¡°íšŒ ì‹¤íŒ¨: {response.status_code} - {response.text[:200]}")
                return []
        except Exception as e:
            logger.error(f"âŒ {table_name} í…Œì´ë¸” ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def extract_basic_statistics(self):
        """ê¸°ë³¸ í†µê³„ ë°ì´í„° ì¶”ì¶œ"""
        logger.info("ğŸ” ê¸°ë³¸ í†µê³„ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        # 1. ì´ íšŒì›ìˆ˜
        users_data = self.get_table_data('users', 'id,subscription_plan,role,total_reports')
        total_users = len(users_data)
        self.stats['ì´_íšŒì›ìˆ˜'] = total_users
        
        # 2. ì´ ë¡œê·¸ì¸ìˆ˜
        login_logs = self.get_table_data('user_login_logs', 'user_id,login_time')
        total_logins = len(login_logs)
        self.stats['ì´_ë¡œê·¸ì¸ìˆ˜'] = total_logins
        
        # 3. ì´ ê²€ìƒ‰ìˆ˜
        search_history = self.get_table_data('search_history', 'user_id,keyword,created_at')
        total_searches = len(search_history)
        self.stats['ì´_ê²€ìƒ‰ìˆ˜'] = total_searches
        
        # 4. ì´ ë¦¬í¬íŠ¸ìƒì„±ìˆ˜ (users í…Œì´ë¸”ì˜ total_reports ì‚¬ìš©)
        total_reports = sum(user.get('total_reports', 0) for user in users_data)
        logger.info(f"ğŸ“Š ë¦¬í¬íŠ¸ ê³„ì‚°: {[user.get('total_reports', 0) for user in users_data]} = {total_reports}")
        self.stats['ì´_ë¦¬í¬íŠ¸ìƒì„±ìˆ˜'] = total_reports
        
        # 5. ìœ ë£Œ/ë¬´ë£Œ íšŒì›ìˆ˜ ê³„ì‚°
        premium_users = 0
        free_users = 0
        admin_users = 0
        
        for user in users_data:
            if user.get('role') == 'admin':
                admin_users += 1
            elif user.get('subscription_plan') == 'premium':
                premium_users += 1
            else:
                free_users += 1
        
        self.stats['ì´_ìœ ë£ŒíšŒì›ìˆ˜'] = premium_users
        self.stats['ì´_ë¬´ë£ŒíšŒì›ìˆ˜'] = free_users
        self.stats['ì´_ê´€ë¦¬ììˆ˜'] = admin_users
        
        logger.info("âœ… ê¸°ë³¸ í†µê³„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
    
    def extract_time_based_data(self):
        """100ì¼ê°„ì˜ ê²€ìƒ‰ì–´ ë° ë¦¬í¬íŠ¸ ì œëª© ì¶”ì¶œ"""
        logger.info("ğŸ” 100ì¼ê°„ ë°ì´í„° ì¶”ì¶œ ì¤‘...")
        
        # 100ì¼ ì „ ë‚ ì§œ ê³„ì‚°
        hundred_days_ago = (datetime.now() - timedelta(days=100)).isoformat()
        
        # 100ì¼ê°„ì˜ ê²€ìƒ‰ì–´
        search_filters = {'created_at': f'gte.{hundred_days_ago}'}
        recent_searches = self.get_table_data('search_history', 'keyword,created_at', search_filters)
        
        search_keywords = []
        for search in recent_searches:
            if search.get('keyword'):
                search_keywords.append(search['keyword'])
        
        self.stats['ì´_ê²€ìƒ‰ì–´_100ì¼'] = len(search_keywords)
        self.stats['ê²€ìƒ‰ì–´_ëª©ë¡_100ì¼'] = search_keywords
        
        # 100ì¼ê°„ì˜ ë¦¬í¬íŠ¸ ì œëª© (ì‹¤ì œ ë¦¬í¬íŠ¸ í…Œì´ë¸”ì´ ì—†ìœ¼ë¯€ë¡œ ë¹ˆ ê°’ìœ¼ë¡œ ì„¤ì •)
        # í–¥í›„ ë¦¬í¬íŠ¸ í…Œì´ë¸”ì´ ìƒì„±ë˜ë©´ ìˆ˜ì • í•„ìš”
        self.stats['ì´_ë¦¬í¬íŠ¸ì œëª©_100ì¼'] = 0
        self.stats['ë¦¬í¬íŠ¸ì œëª©_ëª©ë¡_100ì¼'] = []
        
        logger.info("âœ… 100ì¼ê°„ ë°ì´í„° ì¶”ì¶œ ì™„ë£Œ")
    
    def calculate_averages(self):
        """í‰ê· ê°’ ê³„ì‚°"""
        logger.info("ğŸ” í‰ê· ê°’ ê³„ì‚° ì¤‘...")
        
        total_users = self.stats.get('ì´_íšŒì›ìˆ˜', 0)
        
        if total_users > 0:
            # í‰ê·  ë¡œê·¸ì¸ ìˆ˜
            avg_logins = self.stats.get('ì´_ë¡œê·¸ì¸ìˆ˜', 0) / total_users
            self.stats['í‰ê· _ë¡œê·¸ì¸ìˆ˜'] = round(avg_logins, 2)
            
            # í‰ê·  ê²€ìƒ‰ ìˆ˜
            avg_searches = self.stats.get('ì´_ê²€ìƒ‰ìˆ˜', 0) / total_users
            self.stats['í‰ê· _ê²€ìƒ‰ìˆ˜'] = round(avg_searches, 2)
            
            # í‰ê·  ë¦¬í¬íŠ¸ ìƒì„± ìˆ˜
            avg_reports = self.stats.get('ì´_ë¦¬í¬íŠ¸ìƒì„±ìˆ˜', 0) / total_users
            self.stats['í‰ê· _ë¦¬í¬íŠ¸ìƒì„±ìˆ˜'] = round(avg_reports, 2)
        else:
            self.stats['í‰ê· _ë¡œê·¸ì¸ìˆ˜'] = 0
            self.stats['í‰ê· _ê²€ìƒ‰ìˆ˜'] = 0
            self.stats['í‰ê· _ë¦¬í¬íŠ¸ìƒì„±ìˆ˜'] = 0
        
        logger.info("âœ… í‰ê· ê°’ ê³„ì‚° ì™„ë£Œ")
    
    def calculate_conversion_rates(self):
        """ì „í™˜ìœ¨ ê³„ì‚°"""
        logger.info("ğŸ” ì „í™˜ìœ¨ ê³„ì‚° ì¤‘...")
        
        total_logins = self.stats.get('ì´_ë¡œê·¸ì¸ìˆ˜', 0)
        total_searches = self.stats.get('ì´_ê²€ìƒ‰ìˆ˜', 0)
        total_reports = self.stats.get('ì´_ë¦¬í¬íŠ¸ìƒì„±ìˆ˜', 0)
        
        # ë¡œê·¸ì¸â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨
        if total_logins > 0:
            login_to_report_rate = (total_reports / total_logins) * 100
            self.stats['ë¡œê·¸ì¸_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨'] = round(login_to_report_rate, 2)
        else:
            self.stats['ë¡œê·¸ì¸_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨'] = 0
        
        # ê²€ìƒ‰â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨
        if total_searches > 0:
            search_to_report_rate = (total_reports / total_searches) * 100
            self.stats['ê²€ìƒ‰_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨'] = round(search_to_report_rate, 2)
        else:
            self.stats['ê²€ìƒ‰_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨'] = 0
        
        logger.info("âœ… ì „í™˜ìœ¨ ê³„ì‚° ì™„ë£Œ")
    
    def analyze_keyword_patterns(self):
        """í‚¤ì›Œë“œ ì‚¬ìš© íŒ¨í„´ ë¶„ì„"""
        logger.info("ğŸ” í‚¤ì›Œë“œ íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        search_keywords = self.stats.get('ê²€ìƒ‰ì–´_ëª©ë¡_100ì¼', [])
        
        if search_keywords:
            # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
            keyword_counter = Counter(search_keywords)
            top_keywords = keyword_counter.most_common(10)
            
            # ê³ ìœ  í‚¤ì›Œë“œ ìˆ˜
            unique_keywords = len(set(search_keywords))
            
            self.stats['í‚¤ì›Œë“œ_ë¶„ì„'] = {
                'ì´_í‚¤ì›Œë“œìˆ˜': len(search_keywords),
                'ê³ ìœ _í‚¤ì›Œë“œìˆ˜': unique_keywords,
                'ìƒìœ„_í‚¤ì›Œë“œ': top_keywords,
                'í‰ê· _í‚¤ì›Œë“œ_ê¸¸ì´': round(sum(len(k) for k in search_keywords) / len(search_keywords), 2) if search_keywords else 0
            }
        else:
            self.stats['í‚¤ì›Œë“œ_ë¶„ì„'] = {
                'ì´_í‚¤ì›Œë“œìˆ˜': 0,
                'ê³ ìœ _í‚¤ì›Œë“œìˆ˜': 0,
                'ìƒìœ„_í‚¤ì›Œë“œ': [],
                'í‰ê· _í‚¤ì›Œë“œ_ê¸¸ì´': 0
            }
        
        logger.info("âœ… í‚¤ì›Œë“œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
    
    def analyze_report_patterns(self):
        """ë¦¬í¬íŠ¸ ìƒì„± íŒ¨í„´ ë¶„ì„"""
        logger.info("ğŸ” ë¦¬í¬íŠ¸ íŒ¨í„´ ë¶„ì„ ì¤‘...")
        
        # users í…Œì´ë¸”ì—ì„œ ë¦¬í¬íŠ¸ ê´€ë ¨ ë°ì´í„° ì¡°íšŒ
        users_data = self.get_table_data('users', 'id,total_reports,created_at')
        
        if users_data:
            # ì‚¬ìš©ìë³„ ë¦¬í¬íŠ¸ ìˆ˜ (users í…Œì´ë¸”ì˜ total_reports ì‚¬ìš©)
            user_report_count = {}
            total_reports = 0
            active_users = 0
            
            for user in users_data:
                user_id = user.get('id')
                reports_count = user.get('total_reports', 0)
                if user_id and reports_count > 0:
                    user_report_count[user_id] = reports_count
                    total_reports += reports_count
                    active_users += 1
            
            self.stats['ë¦¬í¬íŠ¸_ë¶„ì„'] = {
                'ì´_ë¦¬í¬íŠ¸ìˆ˜': total_reports,
                'í™œì„±_ì‚¬ìš©ììˆ˜': active_users,
                'í‰ê· _ì‚¬ìš©ìë‹¹_ë¦¬í¬íŠ¸': round(total_reports / active_users, 2) if active_users > 0 else 0,
                'í‰ê· _ì œëª©_ê¸¸ì´': 0,  # ì‹¤ì œ ë¦¬í¬íŠ¸ í…Œì´ë¸”ì´ ì—†ì–´ ê³„ì‚° ë¶ˆê°€
                'ìµœë‹¤_ìƒì„±_ì‹œê°„ëŒ€': (0, 0)  # ì‹¤ì œ ë¦¬í¬íŠ¸ í…Œì´ë¸”ì´ ì—†ì–´ ê³„ì‚° ë¶ˆê°€
            }
        else:
            self.stats['ë¦¬í¬íŠ¸_ë¶„ì„'] = {
                'ì´_ë¦¬í¬íŠ¸ìˆ˜': 0,
                'í™œì„±_ì‚¬ìš©ììˆ˜': 0,
                'í‰ê· _ì‚¬ìš©ìë‹¹_ë¦¬í¬íŠ¸': 0,
                'í‰ê· _ì œëª©_ê¸¸ì´': 0,
                'ìµœë‹¤_ìƒì„±_ì‹œê°„ëŒ€': (0, 0)
            }
        
        logger.info("âœ… ë¦¬í¬íŠ¸ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
    
    def analyze_user_distribution(self):
        """ì‚¬ìš©ì ë¶„í¬ ë¶„ì„"""
        logger.info("ğŸ” ì‚¬ìš©ì ë¶„í¬ ë¶„ì„ ì¤‘...")
        
        total_users = self.stats.get('ì´_íšŒì›ìˆ˜', 0)
        premium_users = self.stats.get('ì´_ìœ ë£ŒíšŒì›ìˆ˜', 0)
        free_users = self.stats.get('ì´_ë¬´ë£ŒíšŒì›ìˆ˜', 0)
        
        if total_users > 0:
            premium_percentage = round((premium_users / total_users) * 100, 2)
            free_percentage = round((free_users / total_users) * 100, 2)
        else:
            premium_percentage = 0
            free_percentage = 0
        
        self.stats['ì‚¬ìš©ì_ë¶„í¬'] = {
            'ë¬´ë£ŒíšŒì›': {'ìˆ˜': free_users, 'ë¹„ìœ¨': f"{free_percentage}%"},
            'ìœ ë£ŒíšŒì›': {'ìˆ˜': premium_users, 'ë¹„ìœ¨': f"{premium_percentage}%"},
            'ì´íšŒì›': total_users
        }
        
        logger.info("âœ… ì‚¬ìš©ì ë¶„í¬ ë¶„ì„ ì™„ë£Œ")
    
    def generate_text_output(self):
        """í…ìŠ¤íŠ¸ ì¶œë ¥ ìƒì„±"""
        logger.info("ğŸ“ í…ìŠ¤íŠ¸ ì¶œë ¥ ìƒì„± ì¤‘...")
        
        output_lines = []
        output_lines.append("=" * 80)
        output_lines.append("ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¶”ì¶œ ê²°ê³¼")
        output_lines.append(f"ìƒì„± ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        output_lines.append("=" * 80)
        output_lines.append("")
        
        # ê¸°ë³¸ í†µê³„
        output_lines.append("ğŸ“Š ê¸°ë³¸ í†µê³„")
        output_lines.append("-" * 40)
        output_lines.append(f"ì´ íšŒì›ìˆ˜: {self.stats.get('ì´_íšŒì›ìˆ˜', 0):,}ëª…")
        output_lines.append(f"ì´ ë¡œê·¸ì¸ìˆ˜: {self.stats.get('ì´_ë¡œê·¸ì¸ìˆ˜', 0):,}ê±´")
        output_lines.append(f"ì´ ê²€ìƒ‰ìˆ˜: {self.stats.get('ì´_ê²€ìƒ‰ìˆ˜', 0):,}ê±´")
        output_lines.append(f"ì´ ë¦¬í¬íŠ¸ìƒì„±ìˆ˜: {self.stats.get('ì´_ë¦¬í¬íŠ¸ìƒì„±ìˆ˜', 0):,}ê±´")
        output_lines.append(f"ì´ ìœ ë£ŒíšŒì›ìˆ˜: {self.stats.get('ì´_ìœ ë£ŒíšŒì›ìˆ˜', 0):,}ëª…")
        output_lines.append(f"ì´ ë¬´ë£ŒíšŒì›ìˆ˜: {self.stats.get('ì´_ë¬´ë£ŒíšŒì›ìˆ˜', 0):,}ëª…")
        output_lines.append("")
        
        # 100ì¼ê°„ ë°ì´í„°
        output_lines.append("ğŸ“… ìµœê·¼ 100ì¼ê°„ ë°ì´í„°")
        output_lines.append("-" * 40)
        output_lines.append(f"ì´ ê²€ìƒ‰ì–´(100ì¼): {self.stats.get('ì´_ê²€ìƒ‰ì–´_100ì¼', 0):,}ê°œ")
        output_lines.append(f"ì´ ë¦¬í¬íŠ¸ ì œëª©(100ì¼): {self.stats.get('ì´_ë¦¬í¬íŠ¸ì œëª©_100ì¼', 0):,}ê°œ")
        output_lines.append("")
        
        # í‰ê· ê°’
        output_lines.append("ğŸ“ˆ í‰ê·  í†µê³„")
        output_lines.append("-" * 40)
        output_lines.append(f"í‰ê·  ë¡œê·¸ì¸ ìˆ˜: {self.stats.get('í‰ê· _ë¡œê·¸ì¸ìˆ˜', 0):.2f}ê±´/íšŒì›")
        output_lines.append(f"í‰ê·  ê²€ìƒ‰ ìˆ˜: {self.stats.get('í‰ê· _ê²€ìƒ‰ìˆ˜', 0):.2f}ê±´/íšŒì›")
        output_lines.append(f"í‰ê·  ë¦¬í¬íŠ¸ ìƒì„± ìˆ˜: {self.stats.get('í‰ê· _ë¦¬í¬íŠ¸ìƒì„±ìˆ˜', 0):.2f}ê±´/íšŒì›")
        output_lines.append("")
        
        # ì „í™˜ìœ¨
        output_lines.append("ğŸ”„ ì „í™˜ìœ¨ ë¶„ì„")
        output_lines.append("-" * 40)
        output_lines.append(f"ë¡œê·¸ì¸â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨: {self.stats.get('ë¡œê·¸ì¸_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨', 0):.2f}%")
        output_lines.append(f"ê²€ìƒ‰â†’ë¦¬í¬íŠ¸ ì „í™˜ìœ¨: {self.stats.get('ê²€ìƒ‰_ë¦¬í¬íŠ¸_ì „í™˜ìœ¨', 0):.2f}%")
        output_lines.append("")
        
        # í‚¤ì›Œë“œ ë¶„ì„
        keyword_analysis = self.stats.get('í‚¤ì›Œë“œ_ë¶„ì„', {})
        output_lines.append("ğŸ” í‚¤ì›Œë“œ ë¶„ì„")
        output_lines.append("-" * 40)
        output_lines.append(f"ì´ í‚¤ì›Œë“œìˆ˜: {keyword_analysis.get('ì´_í‚¤ì›Œë“œìˆ˜', 0):,}ê°œ")
        output_lines.append(f"ê³ ìœ  í‚¤ì›Œë“œìˆ˜: {keyword_analysis.get('ê³ ìœ _í‚¤ì›Œë“œìˆ˜', 0):,}ê°œ")
        output_lines.append(f"í‰ê·  í‚¤ì›Œë“œ ê¸¸ì´: {keyword_analysis.get('í‰ê· _í‚¤ì›Œë“œ_ê¸¸ì´', 0):.2f}ì")
        
        top_keywords = keyword_analysis.get('ìƒìœ„_í‚¤ì›Œë“œ', [])
        if top_keywords:
            output_lines.append("ìƒìœ„ ê²€ìƒ‰ í‚¤ì›Œë“œ:")
            for i, (keyword, count) in enumerate(top_keywords[:5], 1):
                output_lines.append(f"  {i}. {keyword} ({count}íšŒ)")
        output_lines.append("")
        
        # ë¦¬í¬íŠ¸ ë¶„ì„
        report_analysis = self.stats.get('ë¦¬í¬íŠ¸_ë¶„ì„', {})
        output_lines.append("ğŸ“‹ ë¦¬í¬íŠ¸ ë¶„ì„")
        output_lines.append("-" * 40)
        output_lines.append(f"ì´ ë¦¬í¬íŠ¸ìˆ˜: {report_analysis.get('ì´_ë¦¬í¬íŠ¸ìˆ˜', 0):,}ê°œ")
        output_lines.append(f"í™œì„± ì‚¬ìš©ììˆ˜: {report_analysis.get('í™œì„±_ì‚¬ìš©ììˆ˜', 0):,}ëª…")
        output_lines.append(f"í‰ê·  ì‚¬ìš©ìë‹¹ ë¦¬í¬íŠ¸: {report_analysis.get('í‰ê· _ì‚¬ìš©ìë‹¹_ë¦¬í¬íŠ¸', 0):.2f}ê°œ")
        output_lines.append(f"í‰ê·  ì œëª© ê¸¸ì´: {report_analysis.get('í‰ê· _ì œëª©_ê¸¸ì´', 0):.2f}ì")
        
        peak_hour = report_analysis.get('ìµœë‹¤_ìƒì„±_ì‹œê°„ëŒ€', (0, 0))
        if peak_hour[1] > 0:
            output_lines.append(f"ìµœë‹¤ ìƒì„± ì‹œê°„ëŒ€: {peak_hour[0]}ì‹œ ({peak_hour[1]}ê±´)")
        output_lines.append("")
        
        # ì‚¬ìš©ì ë¶„í¬
        user_dist = self.stats.get('ì‚¬ìš©ì_ë¶„í¬', {})
        output_lines.append("ğŸ‘¥ ì‚¬ìš©ì ë¶„í¬")
        output_lines.append("-" * 40)
        free_info = user_dist.get('ë¬´ë£ŒíšŒì›', {})
        premium_info = user_dist.get('ìœ ë£ŒíšŒì›', {})
        output_lines.append(f"ë¬´ë£ŒíšŒì›: {free_info.get('ìˆ˜', 0):,}ëª… ({free_info.get('ë¹„ìœ¨', '0%')})")
        output_lines.append(f"ìœ ë£ŒíšŒì›: {premium_info.get('ìˆ˜', 0):,}ëª… ({premium_info.get('ë¹„ìœ¨', '0%')})")
        output_lines.append(f"ì´ íšŒì›: {user_dist.get('ì´íšŒì›', 0):,}ëª…")
        output_lines.append("")
        
        output_lines.append("=" * 80)
        
        return "\n".join(output_lines)
    
    def save_to_file(self, content):
        """ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"database_statistics_{timestamp}.txt"
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            logger.info(f"ğŸ“ ê²°ê³¼ê°€ {filename} íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            return filename
        except Exception as e:
            logger.error(f"âŒ íŒŒì¼ ì €ì¥ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def run_extraction(self):
        """ì „ì²´ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰"""
        logger.info("ğŸš€ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¶”ì¶œ ì‹œì‘")
        
        # ì—°ê²° í™•ì¸
        if not self.check_connection():
            logger.error("âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨ë¡œ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            return
        
        try:
            # ë°ì´í„° ì¶”ì¶œ ë° ë¶„ì„
            self.extract_basic_statistics()
            self.extract_time_based_data()
            self.calculate_averages()
            self.calculate_conversion_rates()
            self.analyze_keyword_patterns()
            self.analyze_report_patterns()
            self.analyze_user_distribution()
            
            # ê²°ê³¼ ì¶œë ¥
            output_content = self.generate_text_output()
            
            # ì½˜ì†” ì¶œë ¥
            print("\n" + output_content)
            
            # íŒŒì¼ ì €ì¥
            saved_file = self.save_to_file(output_content)
            
            logger.info("âœ… ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¶”ì¶œ ì™„ë£Œ")
            
            if saved_file:
                logger.info(f"ğŸ“ ê²°ê³¼ íŒŒì¼: {saved_file}")
            
        except Exception as e:
            logger.error(f"âŒ ì¶”ì¶œ í”„ë¡œì„¸ìŠ¤ ì˜¤ë¥˜: {str(e)}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("=" * 80)
    print("ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¶”ì¶œê¸°")
    print("Database Statistics Extractor")
    print("=" * 80)
    
    extractor = DatabaseStatisticsExtractor()
    extractor.run_extraction()

if __name__ == "__main__":
    main()